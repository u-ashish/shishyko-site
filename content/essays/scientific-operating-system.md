---
title: "A New Scientific Operating System"
series: "SciOS"
author: "Ashish Uppala"
date: "June 2025"
abstract: "AI, and other 'black swan' events, are set to transform how we do science. This essay explores how we got here, and what a new Scientific Operating System (SciOS) might look like."
---

> Scientific progress on a broad front results from the free play of free intellects, working on subjects of their own choice, in the manner dictated by their curiosity for exploration of the unknown. - Vannevar Bush

In the past, scientists like Newton would withhold sharing findings and instead only share anagrams so they could later prove priority on discovery. It wasn't until the advent of journals that science became more open with more sharing across scientists in various disciplines (see The Royal Society and others).

Today, we take much of this history of science for granted. Breakthroughs like CRISPR, the Human Genome Project, and CAR-T cell therapy demonstrate scienceâ€™s impact on our lives. But behind the scenes, scientists still operate within a system that stifles their creativity and ability to do great science.

Efforts like Open Science have chipped away at these problems, but institutional inertia has limited progress. I argue that two recent shifts -- 1) political upheaval in U.S. federal funding and 2) the rise of generative AI -- create a rare opening for new, enduring models of research funding and infrastructure.

How did we get here? And what does a potential, new Scientific Operating System (SciOS) -- meaning the infrastructure, tools, norms, and institutions that support the full lifecycle of scientific inquiry -- for basic research entail?

## Existing Framework for Scientific Progress

Nurturing systems to promote scientific inquiry and progress -- with respect to research direction, advancement of knowledge, development of technologies in public interest, and the nurture of scientific talent -- is a key concern of any society.

After World War 2, Vannevar Bush wrote his famous memo, *Science, The Endless Frontier* to outline the importance of a framework for relationships between the federal government and universities to maintain global relevance for the United States.

This led to the creation of a framework where the federal government funded basic research done at universities (even without immediate, short-term impact) and ensured we had a pipeline for domestic talent.

Shortly after, we had the Bayh-Dole Act, which intended to ensure that tax-payer funded research would not only advance knowledge, but be translated into technologies, products, or services that benefitted the public.

Universities not only became key pipelines of scientific talent and centers of basic research, but evolved into engines of innovation through Technology Transfer Offices (TTO), and more. They continued to bundle more and more functions into their overall purpose in society.

Over time, others entered the orbit of this budding scientific system. Most notable were scholarly societies and publishers, which started well before as a way to disseminate scientific knowledge, but increasingly cemented themselves with universities to influence how science is done, and how new knowledge is, and is not shared.

## "Science" Today

Scholarly societies began as communities of scientists who found each other, shared their findings, and built on their collective understanding of the world. Though early on, scientists would use anagrams when sharing their findings, journals were eventually formed to streamline the dissemination of scientific knowledge.

As new technologies like the internet emerged, publishers needed to find ways to maintain their relevance. They are, after all, businesses, with a mandate to not just exist, but grow.

One way to create staying power as a publisher is to:

- Monetize access to read, or publish content, which you can defend through copyright laws
- Ensure that people *have to* publish with you by:
	- Creating prestige by defining different levels of importance for journals
	- Building a network of reviewers to review content ready for publication to ensure it's "held to a necessary standard"
	- Ensuring that citations -- the primary mechanism to build on scientific knowledge -- becomes a currency for one's career through impact, rankings, and more, by working with indices and agencies that track these measures
	- Creating secondary mechanisms of career advancement -- through professional networks, and more, mediated by your society.

This is not an evil scheme by publishers tricking everyone else, but an optimization by all players around the perverse incentives they have. 

Consider the perspective of a university, which gets significant revenue through taxpayer dollars via indirect costs on grants: how do we recruit and retain faculty securing those grants?

- Tie faculty tenure to publications, impact, and prestige (with the help of publishers, ranking agencies, and more)
- Work with citation indices and publishers to improve the "brand value" of the university to attract new faculty that might bring more grant revenue

Indeed this is all-too familiar for most scientists, and this became the de-facto system everyone participates in.

And so, journals and publishers, while serving an important, core need, have gradually morphed the system with universities and federal funding into something with a number of issues:

- The creation of silos of information that are not interoperable between research institutes and labs
- A disincentive to publish important findings. Why share something as soon as you have it, if you can mine it for a little more to get ahead of someone else?
- A disincentive to publish negative results
- An inefficient peer-review system built on underpaid (or unpaid) labor, which simply cannot scale with the exponential rate of increase in new publications *(At a recent conference, someone proposed that publishers pay for coffee for reviewers!)*
- An incentive to falsify results -- in egregious but also in subtle ways -- to get more funding.
- Being published is treated like getting a stamp of approval.
- A narrative driven format for scientific findings, instead of a focus on the facts and "knowledge units"

Are there some disciplines in science where these problems are not as big?

I think so, especially in technical fields which have been influenced by Open Source software, which made it easier to embrace Open Science methodology (physics, computer science, ml/ai).

Yet other fields with high impact on society -- life sciences, etc. remain plagued by these issues. Attempts to address these from within are met with significant inertia, making any meaningful change to adapt the system to the digital age virtually impossible.

## A Shifting Federal Landscape

Recent political events that threaten federal research funding and weaponize the federal government against universities are arguably a black swan event. As the federal framework used to fund science is being dismantled, universities are looking for alternative sources of revenue while [facing an unbunding](https://www.unbundle-the-university.com/) of different functions they took on in the last few decades.

Time will tell exactly how this plays out, but these changes are already opening the door for an unbundling of the university TTO function I referenced earlier. Ecosystem developers like [Portal Innovations](https://portalinnovations.com) as well as venture / industry partners are finding new ways to work with universities to help them diversify their sources of revenue through the IP they have.

What I find more interesting is that the shakiness of the federal funding environment makes universities and researchers increasingly more open to exploring new sources of funding for basic research (not just commercialization activity). That means an opening to de-couple the monopolistic grip that universities and publishers have over how science itself is actually done, and a relaxing of some of the constraints around scientists and their careers.

Don't get me wrong. All of this alone is insufficient to topple over an old system and replace it with something new. But that's also besides the point.

What we have, in this moment, is a very, *very* useful wedge to get scientists and universities open minded about new opportunities to fund their interests, which enables groups like [Astera Institute](https://astera.org) or [Convergent Research](https://www.convergentresearch.org/) to experiment with new ways of funding science, on their own terms.

How do we ensure that these new models, if successful, actually stay and work in service of great science? And if they do stay, what foundational should they get in place to start moving the needle on these old incentive structures?

## The Generative AI Moment

Like other industries, many problems within science are structural. They aren't technology problems to be solved through a new app. But, leveraging technology to support a new, modern infrastructure for more open, collaborative science can create the structural shift the system needs and give these new models the necessary power to stay.

While uncertainty at the federal level is creating one set of opportunities around new funding models and infrastructure for basic science, recent advances in large language models unlock our ability to new approaches real staying power.

Many of the mechanisms we've built were predicated on data and information being worked on at what I call *people scale*: the natural limits at which a group of people can reasonably organize and do things (think analysts, peer review, etc.).

What does a new Scientific Operating System look like that preserves the basic tenets of scientific inquiry, without compromising the benefits of science for humanity?

And how can we ensure that it continues to celebrate the people involved in doing great science, without putting the individual above the institution?

A well-designed Scientific Operating System â€” meaning the infrastructure, tools, norms, and institutions that support the full lifecycle of scientific inquiry â€” should _optimize for truth-seeking, openness, collaboration, and impact_.

In essence, it should _let good science happen faster, more reliably, and more inclusively_.

Stated differently, such a system should:

- Continue to fund exploratory research, even without a clear short or medium term ROI, see [Astera Institute for a good example](https://asterainstitute.substack.com/p/scientific-publishing-enough-is-enough)
- Encourage the publication of negative results, which over time will speed up the rate of innovation by mitigating the white space problem
- Support the publication of **knowledge units**, not just fully formed narratives
- Give granular attribution for scientists -- not just first and last authors
- Allow for **continuous iteration** -- meaning publishing intermediate results
- Make all findings accessible, discoverable, and machine-readable
- Make things like replication checks, data sharing, etc. native to the system
- Create norms that reward and incentivize **openness instead of secrecy**
- Ensure scientists can build their prestige in an interpretable way through more granular attribution for their contributions, instead of it being transferred in aggregate by journal impact and authorship position

Though the technology and infrastructure was always possible for some of these (and in fact, is slowly being built -- see DataCite, Crossref, OpenAlex, preprint servers), it feels much more realistic to scale these systems in an agentic world.

Large language models are rapidly getting us to a point where we can:

- Address issues of information overload through agentic systems that can contextually search through and evaluate the relevance of significantly more articles than an individual human (see [Undermind](https://undermind.ai) as one example)
- Have new ways to formulate hypotheses and analyze data (consider [PlutoBio](https://pluto.bio/) and [PotatoAI](https://readysetpotato.com/))
- Make it easier to harmonize different data sources (see [DevanoAI](https://devano.ai/))
- Run faster experiments that we can scale through machine-readable, interoperable data
- Streamline how we communicate findings and build on our existing knowledge

When new models of funding science are combined with new infrastructure and new technology, there's an opportunity to fundamentally transform how basic science (well before we think about commercialization) is done.

## A Once in a Century Rewrite

Scientists are hackers and painters. They are creative, intelligent, logical. They want to express themselves and solve problems they find interesting. The incumbent system oppresses this core desire.

A new Scientific Operating System isn't just a new toolset, or just a new methodology. It's a set of interactions comprised of people, organizations, data infrastructure, and technologies in service of the creatives who do great science, and the public that depends on it.

Universities will still play a critical role in this. But the institutional inertia created by universities, publishers, and a federal funding framework needs to change so the system can adapt and tackle some of the inefficiencies plaguing scientists.

There's overlap with what I'm describing here and different schools of thought around the Open Science movement. I don't intend for this to be a replacement or substitute, but an execution focused lens on a similar problem: opening up science in the digital age.

My hope as I continue to flesh out these thoughts in future essays is to explore questions like:

- What does it mean, in practice, to share findings more frequently, outside of a narrative format (what I refer to as "knowledge units")?
- How do we ensure that we maintain things like attribution, impact while promoting faster experimentation and sharing of results?
- How might that vary by discipline, if at all?
- How do we deal with fragmentation in infrastructure systems?
- How do we preserve confidentiality and invention priority without compromising the rate of progress and collaboration?
- As new researcher workflow tools are built to document results and collaborate, how should data be stored?
- How should we think about data interoperability to foster collaboration (especially as companies try to create lock-in through proprietary data formats)?

...and much more, to create a timely, big picture view of the system while highlighting points of leverage for actionable change.

If you're building toward the future of science â€” as a researcher, technologist, funder, or dreamer â€” would love to chat: shishyko@gmail.com

