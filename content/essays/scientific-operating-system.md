---
title: "A New Scientific Operating System"
series: "SciOS"
author: "Ashish Uppala"
date: "June 2025"
abstract: "AI, and other 'black swan' events, are set to transform how we do science. This essay explores how we got here, and what a new Scientific Operating System (SciOS) might look like."
---

> Scientific progress on a broad front results from the free play of free intellects, working on subjects of their own choice, in the manner dictated by their curiosity for exploration of the unknown. - Vannevar Bush

Would you believe me if I told you, that way back in the day, scientists like Newton would withhold sharing findings and instead only share anagrams so they could later prove priority on discovery?

It wasn't until the advent of journals that science became more open with more sharing across scientists in various disciplines (see The Royal Society and others).

Today, we take much of this history of science for granted.

What most people experience, and think about, are the amazing results of scientific progress - not just intellectually, but in its real impact. Consider the last few decades, which brought CRISPR gene editing, the Human Genome Project, MRI, CAR-T cell therapy (which still feels like science fiction), and more.

And yet, scientists, who are the core of this machine, face a system that actively opresses their fundamental desires through a wonky set of incentives. How much better could things be if we even had a chance at addressing the critical issues our existing system of science produces?

Indeed these problems vary by discipline, and there have been attempts to improve things from within over recent decades (think of Open Science, etc.). But significant institutional inertia made it difficult to meaningfully experiment with new approaches. Until now.

I argue that there are two key events in recent months - at the federal level in the United States, and recent advances in generative AI - that create the necessary opening for new funding models and infrastructure for science to not just enter, but persist.

How did we get here? And what does a potential, new Scientific Operating System (SciOS) for basic research entail?

## Existing Framework for Scientific Progress

Nurturing systems to promote scientific inquiry and progress -- with respect to research direction, advancement of knowledge, development of technologies in public interest, and the nurture of scientific talent -- is a key concern of any society.

After World War 2, Vannevar Bush wrote his famous memo, *Science, The Endless Frontier* to outline the importance of a framework for relationships between the federal government and universities to maintain global relevance for the United States. This led to the creation of a framework where the federal government would fund basic research done at Universities, developed a pipeline for domestic scientific talent, and more.

Shortly after, we had the Bayh-Dole Act, which intended to ensure that tax-payer funded research would not only advance knowledge, but be translated into technologies, products, or services that benefitted the public.

Universities not only became key pipelines of scientific talent and centers of basic research, but evolved into engines of innovation through Technology Transfer Offices (TTO), and more. They continued to bundle more and more functions into their overall purpose in society.

Over time, others entered the orbit of this budding scientific system. Most notable were scholarly societies and publishers, which started well before as a way to disseminate scientific knowledge, but increasingly cemented themselves and influenced how science is done, and how new knowledge is, and is not shared.

## "Science" Today

Scholarly societies began as communities of scientists who found each other, shared their findings, and built on their collective understanding of the world. Though early on, scientists would use anagrams when sharing their findings, journals were eventually formed to streamline the dissemination of scientific knowledge.

As new technologies emerged (the glorious internet), publishers needed to find ways to maintain their relevance - they are, after all, businesses, with a mandate to not just exist, but grow.

One way to create staying power as a publisher is to:

- Monetize access to read, or publish content, which you can defend through copyright laws
- Ensure that people *have to* publish with you by:
	- Creating prestige by defining different levels of importance for journals
	- Building a network of reviewers to review content ready for publication to ensure it's "held to a necessary standard"
	- Ensuring that citations -- the primary mechanism to build on scientific knowledge -- becomes a currency for one's career through impact, rankings, and more, by working with indices and agencies that track these measures
	- Creating secondary mechanisms of career advancement -- through professional networks, and more, mediated by your society.

This is not an evil scheme by publishers tricking everyone else, but an optimization by all players around the perverse incentives they have. 

Consider the perspective of a university, which gets significant revenue through taxpayer dollars via indirect costs on grants: how do we recruit and retain faculty securing those grants?

- Tie faculty tenure to publications, impact, and prestige (with the help of publishers, ranking agencies, and more)
- Work with citation indices and publishers to improve the "brand value" of the university to attract new faculty that might bring more grant revenue

Indeed this is all-too familiar for most scientists, and this became the de-facto system everyone participates in.

And so, journals and publishers, while serving an important, core need, have gradually morphed the system with universities and federal funding into something with a number of issues:

- The creation of silos of information that are not interoperable between research institutes and labs
- A disincentive to publish important findings. Why share something as soon as you have it, if you can mine it for a little more to get ahead of someone else? *(This one I've witnessed first hand when I was doing research)*
- A disincentive to publish negative results
- An inefficient peer-review system built on underpaid (or unpaid) labor, which simply cannot scale with the exponential rate of increase in new publications *(At a recent conference, someone proposed that publishers pay for coffee for reviewers!)*
- An incentive to falsify results -- in egregious but also in subtle ways -- to get more funding.
- Being published is treated like getting a stamp of approval.
- A narrative driven format for scientific findings, instead of a focus on the facts and "knowledge units"

Are there some disciplines in science where these problems are not as big?

I think so, especially in technical fields which have been influenced by Open Source software, which made it easier to embrace Open Science methodology (physics, computer science, ml/ai).

Yet other fields with high impact on society -- life sciences, etc. remain plagued by these issues. While there are attempts to experiment from within, they're met with significant inertia, making incremental or drastic change to adapt it to the digital age virtually impossible.

## A Shifting Federal Landscape

Recent political events are (arguably) a black swan event. Much of the federal framework used to fund science is being dismantled, and universities are looking for alternative sources of revenue while [facing an unbunding](https://www.unbundle-the-university.com/) of different functions they took on in the last few decades.

Time will tell exactly how this plays out, but these changes are already opening the door for new models of experimentation between universities and ecosystem developers (venture, foundations, etc.) like [Portal Innovations](https://portalinnovations.com) and industry to diversify revenue streams.  This shift is the beginning of an unbundling of University TTO function that I referenced earlier.

What I find more interesting / opportunistic is that the shakiness of the federal funding environment makes universities and researchers increasingly more open to exploring new sources of funding for basic research. That means an opening to de-couple the monopolistic grip that universities and publishers have over how science itself is actually done, and a relaxing of some of the constraints around scientists and their careers.

Don't get me wrong. All of this alone is probably insufficient to topple over an old system and replace it with something new. But that's also besides the point.

What we have, in this moment, is a very, *very* useful wedge to get scientists and universities open minded about new opportunities to bring money in, which enables groups like [Astera Institute](https://astera.org) or [Convergent Research](https://www.convergentresearch.org/) to experiment with new ways of funding science, on their own terms.

How do we ensure that these new models, if successful, actually stay? And if they do stay, what foundational work should they get in place, to start moving the needle on these old incentive structures?

## The Generative AI Moment

Like other industries, many problems are structural. They aren't technology problems to be solved through a new app. But, leveraging technology to support a new, modern infrastructure for more open, collaborative science can create the structural shift the system needs and give these new models the necessary power to stay.

If uncertainty at the federal level is creating one set of opportunities around scientific inquiry and commercialization, recent advances in large language models unlock our ability to give new scientific infrastructure real staying power.

Many of the mechanisms we've built were predicated on data and information being worked on at what I call "people scale": the natural limits at which a group of people can reasonably organize and do things (think analysts, peer review, etc.).

What does a new scientific operating system (SciOS) look like that preserves the basic tenets of scientific inquiry, without compromising the benefits of science for humanity? And how can we ensure that it continues to celebrate the people involved in doing great science, without putting the individual above the institution?

A well-designed scientific operating system — meaning the infrastructure, tools, norms, and institutions that support the full lifecycle of scientific inquiry — should _optimize for truth-seeking, openness, collaboration, and impact_.

In essence, it should _let good science happen faster, more reliably, and more inclusively_.

Stated differently, such a system should:

- Continue to fund exploratory research, even without a clear short or medium term ROI, see [Astera Institute for a good example](https://asterainstitute.substack.com/p/scientific-publishing-enough-is-enough)
- Encourage the publication of negative results, which over time will speed up the rate of innovation by mitigating the white space problem
- Support the publication of **knowledge units**, not just fully formed narratives
- Give granular attribution for scientists -- not just first and last authors
- Allow for **continuous iteration** -- meaning publishing intermediate results
- Make all findings accessible, discoverable, and machine-readable
- Make things like replication checks, data sharing, etc. native to the system
- Create norms that reward and incentivize **openness instead of secrecy**
- Ensure scientists can build their prestige in an interpretable way through more granular attribution for their contributions, instead of it being transferred in aggregate by journal impact and authorship position

Though the technology and infrastructure was always possible for some of these (and in fact, is slowly being built -- see DataCite, Crossref, OpenAlex, preprint servers), it feels much more realistic to scale these systems in an agentic world. Large language models are rapidly getting us to a point where we can:

- Address issues of information overload through agentic systems that can contextually evaluate the relevance of significantly more articles than an individual human
- Have new ways to formulate hypotheses and analyze data, creating room for more experimentation, faster iteration, and more consistent, interoperable data sharing
- Streamline how we communicate findings and build on our knowledge with the help of reasoning models

When new models of funding science are combined with new technologies and new infrastructure, there's an opportunity to fundamentally transform how basic science (pre, pre-commercialization) is done.

## A Once in a Century Rewrite

Scientists are hackers and painters. They are creative, intelligent, logical. They want to express themselves and solve problems they find interesting. The incumbent system oppresses this core desire.

A new Scientific Operating System isn't just a new toolset, or just a new methodology. It's a set of interactions comprised of people, organizations, data infrastructure, and technologies in service of the creatives who do great science, and the public that depends on it.

There's definitely overlap with what I'm describing here and different schools of thought around the Open Science movement. I don't intend for this to be a replacement or substitute, but a different lens on a similar problem: _how_ we actually open up science in the digital age.

We're already seeing new approaches for funding outside of the government. What we need next is a set of standards, infrastructure, and technology to take this one step further.

My hope as I continue to flesh out these thoughts in future essays is to explore questions like:

- How should experiments, results, and findings ("knowledge units") be stored and shared in a data-first world to speed up the rate of experimentation?
- How might that vary by discipline?
- What do attribution and measures of impact look like in a knowledge unit world?
- How do we preserve confidentiality and invention priority without compromising the rate of progress and collaboration?
- As new researcher workflow tools are built to document results and collaborate, how should data be stored? How should we think about data interoperability to foster collaboration?

...and much more, to create a timely, big picture view of the system while highlighting points of leverage for actionable change.

If you're building toward the future of science — as a researcher, technologist, funder, or dreamer — would love to chat: shishyko@gmail.com

